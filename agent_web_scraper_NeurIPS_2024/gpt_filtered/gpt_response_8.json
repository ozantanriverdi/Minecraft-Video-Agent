[
    {"title": "MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models", "relevant": false},
    {"title": "Is Your LiDAR Placement Optimized for 3D Scene Understanding?", "relevant": false},
    {"title": "Benign overfitting in leaky ReLU networks with moderate input dimension", "relevant": false},
    {"title": "Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss", "relevant": false},
    {"title": "StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation", "relevant": false},
    {"title": "Slight Corruption in Pre-training Data Makes Better Diffusion Models", "relevant": false},
    {"title": "Autoregressive Image Generation without Vector Quantization", "relevant": false},
    {"title": "Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare", "relevant": false},
    {"title": "Acoustic Volume Rendering for Neural Impulse Response Fields", "relevant": false},
    {"title": "BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning", "relevant": false},
    {"title": "PACE: marrying the generalization of PArameter-efficient fine-tuning with Consistency rEgularization", "relevant": false},
    {"title": "Dynamic 3D Gaussian Fields for Urban Areas", "relevant": false},
    {"title": "Principled Bayesian Optimization in Collaboration with Human Experts", "relevant": false},
    {"title": "3DET-Mamba: Causal Sequence Modelling for End-to-End 3D Object Detection", "relevant": false},
    {"title": "No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery", "relevant": false},
    {"title": "Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI", "relevant": false},
    {"title": "The Implicit Bias of Gradient Descent on Separable Multiclass Data", "relevant": false},
    {"title": "How many classifiers do we need?", "relevant": false},
    {"title": "Learning to Reason via Program Generation, Emulation, and Search", "relevant": false},
    {"title": "Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects", "relevant": false},
    {"title": "FactorizePhys: Matrix Factorization for Multidimensional Attention in Remote Physiological Sensing", "relevant": false},
    {"title": "Multi-Group Proportional Representation in Retrieval", "relevant": false},
    {"title": "NeuralSteiner: Learning Steiner Tree for Overflow-avoiding Global Routing in Chip Design", "relevant": false},
    {"title": "The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations", "relevant": false},
    {"title": "Limits of Transformer Language Models on Learning to Compose Algorithms", "relevant": false},
    {"title": "Constrained Diffusion Models via Dual Training", "relevant": false},
    {"title": "Universality in Transfer Learning for Linear Models", "relevant": false},
    {"title": "Gorilla: Large Language Model Connected with Massive APIs", "relevant": false},
    {"title": "Stepping Forward on the Last Mile", "relevant": false},
    {"title": "Semi-Random Matrix Completion via Flow-Based Adaptive Reweighting", "relevant": false},
    {"title": "Discovering plasticity rules that organize and maintain neural circuits", "relevant": false},
    {"title": "Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution", "relevant": false},
    {"title": "Unelicitable Backdoors via Cryptographic Transformer Circuits", "relevant": false},
    {"title": "Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale", "relevant": true},
    {"title": "Learning Group Actions on Latent Representations", "relevant": false},
    {"title": "Neural Embeddings Rank: Aligning 3D latent dynamics with movements", "relevant": false},
    {"title": "Understanding the Limits of Vision Language Models Through the Lens of the Binding Problem", "relevant": false},
    {"title": "Sample Efficient Bayesian Learning of Causal Graphs from Interventions", "relevant": false},
    {"title": "Non-asymptotic Convergence of Training Transformers for Next-token Prediction", "relevant": false},
    {"title": "Active, anytime-valid risk controlling prediction sets", "relevant": false},
    {"title": "What Makes and Breaks Safety Fine-tuning? A Mechanistic Study", "relevant": false},
    {"title": "Semantics and Spatiality of Emergent Communication", "relevant": false},
    {"title": "Sample-Efficient Geometry Reconstruction from Euclidean Distances using Non-Convex Optimization", "relevant": false},
    {"title": "Normalization Layer Per-Example Gradients are Sufficient to Predict Gradient Noise Scale in Transformers", "relevant": false},
    {"title": "Reducing Transformer Key-Value Cache Size with Cross-Layer Attention", "relevant": false},
    {"title": "Symmetry Discovery Beyond Affine Transformations", "relevant": false},
    {"title": "On the Inductive Bias of Stacking Towards Improving Reasoning", "relevant": false},
    {"title": "Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory", "relevant": false},
    {"title": "Inductive biases of multi-task learning and finetuning: multiple regimes of feature reuse", "relevant": false},
    {"title": "Communication Efficient Distributed Training with Distributed Lion", "relevant": false}
]
