[
    {"title": "SA3DIP: Segment Any 3D Instance with Potential 3D Priors", "relevant": false},
    {"title": "Voila-A: Aligning Vision-Language Models with User's Gaze Attention", "relevant": false},
    {"title": "Barely Random Algorithms and Collective Metrical Task Systems", "relevant": false},
    {"title": "Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning", "relevant": false},
    {"title": "Latent Intrinsics Emerge from Training to Relight", "relevant": false},
    {"title": "Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts", "relevant": false},
    {"title": "Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom", "relevant": false},
    {"title": "Kermut: Composite kernel regression for protein variant effects", "relevant": false},
    {"title": "Automatically Learning Hybrid Digital Twins of Dynamical Systems", "relevant": false},
    {"title": "On the Identifiability of Poisson Branching Structural Causal Model Using Probability Generating Function", "relevant": false},
    {"title": "Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations", "relevant": false},
    {"title": "Can Transformers Smell Like Humans?", "relevant": false},
    {"title": "Geodesic Optimization for Predictive Shift Adaptation on EEG data", "relevant": false},
    {"title": "Second-order forward-mode optimization of recurrent neural networks for neuroscience", "relevant": false},
    {"title": "Discrete Flow Matching", "relevant": false},
    {"title": "Motion Forecasting in Continuous Driving", "relevant": false},
    {"title": "Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality", "relevant": false},
    {"title": "Moving Off-the-Grid: Scene-Grounded Video Representations", "relevant": false},
    {"title": "Saliency-driven Experience Replay for Continual Learning", "relevant": false},
    {"title": "Adversarial Environment Design via Regret-Guided Diffusion Models", "relevant": false},
    {"title": "Localized Zeroth-Order Prompt Optimization", "relevant": false},
    {"title": "Molecule Design by Latent Prompt Transformer", "relevant": false},
    {"title": "Do causal predictors generalize better to new domains?", "relevant": false},
    {"title": "Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference", "relevant": false},
    {"title": "Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss", "relevant": false},
    {"title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention", "relevant": false},
    {"title": "Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration", "relevant": false},
    {"title": "Humanoid Locomotion as Next Token Prediction", "relevant": true},
    {"title": "NeoRL: Efficient Exploration for Nonepisodic RL", "relevant": false},
    {"title": "Toxicity Detection for Free", "relevant": false},
    {"title": "Conditioning non-linear and infinite-dimensional diffusion processes", "relevant": false},
    {"title": "Semi-supervised Multi-label Learning with Balanced Binary Angular Margin Loss", "relevant": false},
    {"title": "Automated Efficient Estimation using Monte Carlo Efficient Influence Functions", "relevant": false},
    {"title": "Sample-Efficient Private Learning of Mixtures of Gaussians", "relevant": false},
    {"title": "Optimal ablation for interpretability", "relevant": false},
    {"title": "A Pairwise Pseudo-likelihood Approach for Matrix Completion with Informative Missingness", "relevant": false},
    {"title": "Training Compute-Optimal Protein Language Models", "relevant": false},
    {"title": "ReFT: Representation Finetuning for Language Models", "relevant": false},
    {"title": "Deep Submodular Peripteral Networks", "relevant": false},
    {"title": "Provable Benefit of Cutout and CutMix for Feature Learning", "relevant": false},
    {"title": "Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning", "relevant": false},
    {"title": "Fine Tuning Out-of-Vocabulary Item Recommendation with User Sequence Imagination", "relevant": false},
    {"title": "Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data", "relevant": false},
    {"title": "Don't Look Twice: Faster Video Transformers with Run-Length Tokenization", "relevant": false},
    {"title": "Poisson Variational Autoencoder", "relevant": false},
    {"title": "A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks", "relevant": false},
    {"title": "Deep Learning for Computing Convergence Rates of Markov Chains", "relevant": false},
    {"title": "Diffusion Models With Learned Adaptive Noise", "relevant": false},
    {"title": "Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers", "relevant": false},
    {"title": "Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences", "relevant": false}
]
