SymDiff: Equivariant Diffusion via Stochastic Symmetrisation
GUD: Generation with Unified Diffusion
On the Role of Depth and Looping for In-Context Learning with Task Diversity
AdaWM: Adaptive World Model based Planning for Autonomous Driving
GraphRCG: Self-Conditioned Graph Generation
A Meta-Learning Approach to Bayesian Causal Discovery
Inference Scaling for Long-Context Retrieval Augmented Generation
The Geometry of Tokens in Internal Representations of Large Language Models
Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding
Is Your Video Language Model a Reliable Judge?
Boosting Multiple Views for pretrained-based Continual Learning
Explain Like I'm Five: Using LLMs to Improve PDE Surrogate Models with Text
Towards Effective Discrimination Testing for Generative AI
Evaluating Information Gathering Abilities of Large Language Models with QuestBench
Adaptively Private Next-Token Prediction of Large Language Models
IAUNet: Instance-Aware U-Net
Compact Multimodal Context Represenations Using Visual Tokens
ChipVQA: Benchmarking Visual Language Models for Chip Design
Towards Sampling Data Structures for Tensor Products
Persistent Similarity in Internal Representations of Large Language Models
Scaling Test-Time Compute Optimally Can be More Effective than Scaling LLM Parameters
Matrix Product Sketching via Coordinated Sampling
A Phase Transition Induces Catastrophic Overfitting in Adversarial Training
RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze
DUET: Decentralized Bilevel Optimization without Lower-Level Strong Convexity
Preserving Deep Representations in One-Shot Pruning: A Hessian-Free Second-Order Optimization Framework
Characterizing Context Influence and Hallucination in Summarization
Capturing the Temporal Dependence of Training Data Influence
FEABench: Evaluating Language Models on Real World Physics Reasoning Ability
Learning from Preferences and Mixed Demonstrations in General Settings
Wasserstein Distances, Neuronal Entanglement, and Sparsity
Unstable Unlearning: The Hidden Risk of Concept Resurgence in Diffusion Models
Chemistry-Inspired Diffusion with Non-Differentiable Guidance
A Simple Baseline for Predicting Future Events with Auto-Regressive Tabular Transformers
On the Convergence of Adam-Type Algorithms for Bilevel Optimization under Unbounded Smoothness
Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning
No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data
Lie Group-Induced Dynamics in Score-Based Generative Modeling
Aligning Language Models with Demonstrated Feedback
Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle
Adversarial Robustness of In-Context Learning in Transformers for Linear Regression
See It from My Perspective: How Language Affects Cultural Bias in Image Understanding
Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities
MOREL: Enhancing Adversarial Robustness through Multi-Objective Representation Learning
CELL-Diff: Unified Diffusion Modeling for Protein Sequences and Microscopy Images
Do Mice Grok? Glimpses of Hidden Progress in Sensory Cortex
Test-Time RAG: Enhancing Long Context Understanding in LLMs with Retrieval-Augmented Mechanisms
WaveDiffusion: Exploring Full Waveform Inversion via Joint Diffusion in the Latent Space
Predictive Differential Training Guided by Training Dynamics
Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration
