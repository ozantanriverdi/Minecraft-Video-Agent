[
    {"title": "Searching For Robust Point Cloud Distillation", "relevant": false},
    {"title": "Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs", "relevant": false},
    {"title": "DUALFormer: A Dual Graph Convolution and Attention Network for Node Classification", "relevant": false},
    {"title": "Hierarchical Preference Optimization: Learning to achieve goals via feasible subgoals prediction", "relevant": false},
    {"title": "Hessian-Free Natural Gradient Descent for Physics Informed Machine Learning", "relevant": false},
    {"title": "Revisiting Delta-Parameter Pruning For Fine-Tuned Models", "relevant": false},
    {"title": "CREIMBO: Cross-Regional Ensemble Interactions in Multi-view Brain Observations", "relevant": false},
    {"title": "Progress or Regress? Self-Improvement Reversal in Post-training", "relevant": false},
    {"title": "Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation", "relevant": false},
    {"title": "CoCMT: Towards Communication-Efficient Corss-Modal Transformer For Collaborative Perception", "relevant": false},
    {"title": "The Graph's Apprentice: Teaching an LLM Low-Level Knowledge for Circuit Quality Estimation", "relevant": false},
    {"title": "FedL2G: Learning to Guide Local Training in Heterogeneous Federated Learning", "relevant": false},
    {"title": "Detecting Hallucination Before Answering: Semantic Compression Through Instruction", "relevant": false},
    {"title": "Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation", "relevant": false},
    {"title": "Speculative Streaming: Fast LLM Inference without Auxiliary Models", "relevant": false},
    {"title": "Data-Driven Creativity: Amplifying Imagination in LLM Writing", "relevant": false},
    {"title": "FTP: Efficient Prefilling for Long-Context LLM Inference via FFN Token Pruning", "relevant": false},
    {"title": "MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models", "relevant": false},
    {"title": "ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs", "relevant": false},
    {"title": "The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise", "relevant": false},
    {"title": "CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing", "relevant": false},
    {"title": "Pacmann: Efficient Private Approximate Nearest Neighbor Search", "relevant": false},
    {"title": "h4rm3l: A Language for Composable Jailbreak Attack Synthesis", "relevant": false},
    {"title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models", "relevant": true},
    {"title": "A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage", "relevant": false},
    {"title": "On Evaluating the Durability of Safeguards for Open-Weight LLMs", "relevant": false},
    {"title": "Donâ€™t Throw Away Data: Better Sequence Knowledge Distillation", "relevant": false},
    {"title": "Contradiction Retrieval Via Sparse-Aware Sentence Embedding", "relevant": false},
    {"title": "QAC:Quantization-Aware Conversion for Mixed-Timestep Spiking Neural Networks", "relevant": false},
    {"title": "SlimLLaVA: Automatic Pruning for Large Vision-language Models", "relevant": false},
    {"title": "Learngene Tells You How to Customize: Task-Aware Parameter Prediction at Flexible Scales", "relevant": false},
    {"title": "The 'Law' of the Unconscious Contrastive Learner: Probabilistic Alignment of Unpaired Modalities", "relevant": false},
    {"title": "Graph Neural Preconditioners for Iterative Solutions of Sparse Linear Systems", "relevant": false},
    {"title": "Flow of Reasoning: Training LLMs for Divergent Problem Solving with Minimal Examples", "relevant": false},
    {"title": "A Robust Method to Discover Causal or Anticausal Relation", "relevant": false},
    {"title": "Evaluating Ranking Loss Functions in Performance Predictor for NAS", "relevant": false},
    {"title": "An Empirical Analysis of Uncertainty in Large Language Model Evaluations", "relevant": false},
    {"title": "Effects of Scale on Language Model Robustness", "relevant": false},
    {"title": "ChuLo: Chunk-Level Key Information Representation for Efficient Long Document Processing", "relevant": false},
    {"title": "Hawkes process revisited: balancing interpretability and flexibility with contextualized event embeddings and a neural impact kernel", "relevant": false},
    {"title": "FedDES: A Discrete-Event Simulator For Large-Scale Federated Learning", "relevant": false},
    {"title": "On Large Language Model Continual Unlearning", "relevant": false},
    {"title": "Structural Probing with Feature Interaction", "relevant": false},
    {"title": "Forming Scalable, Convergent GNN Layers that Minimize a Sampling-Based Energy", "relevant": false},
    {"title": "MissDiff: Training Diffusion Models on Tabular Data with Missing Values", "relevant": false},
    {"title": "Robult: A Scalable Framework for Semi-Supervised Multimodal Learning with Missing Modalities", "relevant": false},
    {"title": "Visual Prompting Reimagined: The Power of Activation Prompts", "relevant": false},
    {"title": "Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaption", "relevant": false},
    {"title": "Correlational Lagrangian Schrodinger Bridge: Learning Dynamics with Population-Level Regularization", "relevant": false},
    {"title": "Underestimated Privacy Risks for Minority Populations in Large Language Model Unlearning", "relevant": false}
]
