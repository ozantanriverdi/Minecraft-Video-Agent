[
    {"title": "Fengbo: a Clifford Neural Operator pipeline for 3D PDEs in Computational Fluid Dynamics", "relevant": false},
    {"title": "MolGene-E: Inverse Molecular Design to Modulate Single Cell Transcriptomics", "relevant": false},
    {"title": "MeshLRM: Large Reconstruction Model for High-Quality Meshes", "relevant": false},
    {"title": "Attacking Audio Language Models with Best-of-N Jailbreaking", "relevant": false},
    {"title": "Recurrent Drafter for Fast Speculative Decoding in Large Language Models", "relevant": false},
    {"title": "Advantage Alignment Algorithms", "relevant": false},
    {"title": "Leveraging Natural Frequency Deviation for Diffusion-Generated Image Detection", "relevant": false},
    {"title": "Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis", "relevant": false},
    {"title": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "relevant": false},
    {"title": "DO GENERATIVE MODELS LEARN RARE GENERATIVE FACTORS?", "relevant": false},
    {"title": "Improving Soft Unification with Knowledge Graph Embedding Methods", "relevant": false},
    {"title": "Superpipeline: A Universal Approach for Reducing GPU Memory Usage in Large Models", "relevant": false},
    {"title": "The Inductive Bias of Minimum-Norm Shallow Diffusion Models That Perfectly Fit the Data", "relevant": false},
    {"title": "Democratizing Evaluation with Infinity-Benchmarks: Sample-Level Heterogeneous Testing Over Arbitrary Capabilities", "relevant": false},
    {"title": "No Access, No Safety: Free Lunch Adversarial Attacks on Black-box NLP Models", "relevant": false},
    {"title": "Edge Importance Inference Towards Neighborhood Aware GNNs", "relevant": false},
    {"title": "3D-free meets 3D priors: Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance", "relevant": false},
    {"title": "Does learning the right latent variables necessarily improve in-context learning?", "relevant": false},
    {"title": "Needle Threading: Can LLMs Follow Threads Through Near-Million-Scale Haystacks?", "relevant": false},
    {"title": "Hough Voting-based Prompt Learning for Segment Anything Model", "relevant": false},
    {"title": "SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language Model", "relevant": true},
    {"title": "Supervised Contrastive Block Disentanglement", "relevant": false},
    {"title": "Task Diversity Shortens the ICL Plateau", "relevant": false},
    {"title": "Distributed In-Context Learning under Non-IID Among Clients", "relevant": false},
    {"title": "Optimal Protocols for Continual Learning via Statistical Physics and Control Theory", "relevant": false},
    {"title": "BOIL: Learning Environment Personalized Information", "relevant": false},
    {"title": "Do Unlearning Methods Remove Information from Language Model Weights?", "relevant": false},
    {"title": "Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation", "relevant": false},
    {"title": "Understanding the Connection between Low-Dimensional Representation and Generalization via Interpolation", "relevant": false},
    {"title": "Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark", "relevant": false},
    {"title": "A Hitchhiker's Guide to Scaling Law Estimation", "relevant": false},
    {"title": "Generation and Evaluation of Synthetic Data Containing Treatments", "relevant": false},
    {"title": "A Manifold Perspective on the Statistical Generalization of Graph Neural Networks", "relevant": false},
    {"title": "Self-Training on Unpaired Data Improves Multi-Modal Alignment", "relevant": false},
    {"title": "Attic: A New Architecture for Tabular In-Context Learning Transformers", "relevant": false},
    {"title": "Spatially-aware Photo-realistic Face Relighting using Joint Embedding of Light Properties", "relevant": false},
    {"title": "Fine-tuned In-Context Learning Transformers are Excellent Tabular Data Classifiers.", "relevant": false},
    {"title": "Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit", "relevant": false},
    {"title": "Do Symbolic or Black-Box Representations Generalise Better In Learned Optimisation?", "relevant": false},
    {"title": "PAD: Personalized Alignment at Decoding-time", "relevant": false},
    {"title": "Next state prediction gives rise to entangled, yet compositional representations of objects", "relevant": false},
    {"title": "De-biasing Diffusion: Data-Free FP8 Quantization of Text-to-Image Models with Billions of Parameters", "relevant": false},
    {"title": "BiCompFL: Stochastic Federated Learning with Bi-Directional Compression", "relevant": false},
    {"title": "MarDini: Masked Autoregressive Diffusion for Video Generation at Scale", "relevant": false},
    {"title": "Foldable SuperNets: Scalable Merging of Transformers with Different Initializations and Tasks", "relevant": false},
    {"title": "LLM Pruning and Distillation in Practice", "relevant": false},
    {"title": "Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation", "relevant": false},
    {"title": "Temporal Prompting Matters: Rethinking Referring Video Object Segmentation", "relevant": false},
    {"title": "Learning Arbitrary Logical Formula as a Sparse Neural Network Module", "relevant": false},
    {"title": "Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes", "relevant": false}
]
