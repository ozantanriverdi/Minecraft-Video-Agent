[
    {"title": "Policy Design in Long-run Welfare Dynamics", "relevant": false},
    {"title": "Contextual Experience Replay for Continual Learning of Language Agents", "relevant": false},
    {"title": "Dynamic Modeling of Patients, Modalities and Tasks via Multi-modal Multi-task Mixture of Experts", "relevant": false},
    {"title": "Backdooring Bias into Text-to-Image Models", "relevant": false},
    {"title": "Seeing the Whole in the Parts in Self-Supervised Representation Learning", "relevant": false},
    {"title": "Procedural Synthesis of Synthesizable Molecules", "relevant": false},
    {"title": "Recurrent Action Transformer with Memory", "relevant": false},
    {"title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning", "relevant": false},
    {"title": "On the Limitation and Redundancy of Transformers: A Rank Perspective", "relevant": false},
    {"title": "PEDVLM: PEDESTRIAN VISION LANGUAGE MODEL FOR INTENTIONS PREDICTION", "relevant": false},
    {"title": "Improving Inverse Folding for Peptide Design with Diversity-Regularized Direct Preference Optimization", "relevant": false},
    {"title": "Multimodal Structure Preservation Learning", "relevant": false},
    {"title": "Building Generalist Robot Policy from Pre-trained Visual Representations", "relevant": false},
    {"title": "On Learning Representations for Tabular Dataset Distillation", "relevant": false},
    {"title": "P-SPIKESSM: HARNESSING PROBABILISTIC SPIKING STATE SPACE MODELS FOR LONG-RANGE DEPENDENCY TASKS", "relevant": false},
    {"title": "Speeding Up Image Classifiers with Little Companions", "relevant": false},
    {"title": "A Kernel Perspective on Training-Free Few-Shot Adaptation of Large Vision-Language Models", "relevant": false},
    {"title": "Better autoregressive regression with LLMs", "relevant": false},
    {"title": "100 instances is all you need: predicting LLM success by testing on a few instances", "relevant": false},
    {"title": "Trained Transformer Classifiers Generalize and Exhibit Benign Overfitting In-Context", "relevant": false},
    {"title": "ReferPix2Pix: Guiding  Multi-Modal LLMs for Image Editing with Referential Pixel Grounding", "relevant": false},
    {"title": "Bayesian Learning of Adaptive Koopman Operator with Application to Robust Motion Planning for Autonomous Trucks", "relevant": false},
    {"title": "PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs", "relevant": false},
    {"title": "FoundationForensics: Traceback Backdoor Attacks for Vision Foundation Models", "relevant": false},
    {"title": "Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra", "relevant": false},
    {"title": "Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?", "relevant": false},
    {"title": "Model Collapse in the Chain of Diffusion Finetuning: A Novel Perspective from Quantitative Trait Modeling", "relevant": false},
    {"title": "SSPictR: Spatial Semantic Pointer Picture Representation", "relevant": false},
    {"title": "Revisiting the Superficial Alignment Hypothesis", "relevant": false},
    {"title": "COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement", "relevant": false},
    {"title": "Hierarchical Clustering for Conditional Diffusion in Image Generation", "relevant": false},
    {"title": "FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models", "relevant": false},
    {"title": "Soft Checksums to Flag Untrustworthy Machine Learning Surrogate Predictions and Application to Atomic Physics Simulations", "relevant": false},
    {"title": "MetaInv: Overcoming Iterative and Direct Method Limitations for Inverse Learning", "relevant": false},
    {"title": "DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search", "relevant": false},
    {"title": "Learning Diagrams: A Graphical Language for Compositional Training Regimes", "relevant": false},
    {"title": "Differential learning kinetics govern the transition from memorization to generalization during in-context learning", "relevant": false},
    {"title": "Joint Graph Rewiring and Feature Denoising via Spectral Resonance", "relevant": false},
    {"title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions", "relevant": false},
    {"title": "Strategic Filtering for Content Moderation: Free Speech or Free of Distortion?", "relevant": false},
    {"title": "Review and Rebuttal: Zero-shot In-context Adversarial Learning for Improving Research Ideation", "relevant": false},
    {"title": "Towards Efficient Confidence Estimation for Large Language Model Reasoning", "relevant": false},
    {"title": "”DOES YOUR MOBILE SUIT YOUR SKIN?”: ADDRESSING SKIN TONE DISPARITIES IN PRESENTATION ATTACK DETECTION FOR ENHANCED INCLUSIVITY OF SMARTPHONE SECURITY", "relevant": false},
    {"title": "Context-Scaling versus Task-Scaling in In-Context Learning", "relevant": false},
    {"title": "Practical alignment requires more than learning from human feedback", "relevant": false},
    {"title": "Performance Control in Early Exiting to Deploy Large Models at the Same Cost of Smaller Ones", "relevant": false},
    {"title": "Latent Feature Mining for Predictive Model Enhancement with Large Language Models", "relevant": false},
    {"title": "Multi-session, multi-task neural decoding from distinct cell-types and brain regions", "relevant": false},
    {"title": "Toward Robust Real-World Audio Deepfake Detection: Closing the Explainability Gap", "relevant": false},
    {"title": "Reality Only Happens Once: Single-path Generalization Bounds for Transformers", "relevant": false}
]
