[
    {"title": "Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding", "relevant": false},
    {"title": "Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces", "relevant": false},
    {"title": "Mousterian: exploring the equivalence of generative and real data augmentation in classification", "relevant": false},
    {"title": "Unearthing Skill-level Insights for Understanding Trade-offs of Foundation Models", "relevant": false},
    {"title": "Learning Imbalanced Data with Beneficial Label Noise", "relevant": false},
    {"title": "Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining", "relevant": false},
    {"title": "Decoupling Layout from Glyph in Online Chinese Handwriting Generation", "relevant": false},
    {"title": "MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts", "relevant": false},
    {"title": "LAST: Latent Structure guided Gaussian Splatting from Monocular Human Videos", "relevant": false},
    {"title": "Residual Connections Harm Generative Representation Learning", "relevant": false},
    {"title": "Well-NeRF: Ensuring Well-Posed Neural Radiance Fields via View Frustum and Shadow Zone Based Regularization", "relevant": false},
    {"title": "HyperINF: Unleashing the HyperPower of the Schulz's Method for Data Influence Estimation", "relevant": false},
    {"title": "SketchFill: Sketch-Guided Code Generation for Imputing Derived Missing Values", "relevant": false},
    {"title": "Which Tasks Should Be Compressed Together? A Causal Discovery Approach for Efficient Multi-Task Representation Compression", "relevant": false},
    {"title": "Compositional Hardness of Code in Large Language Models - A Probabilistic Perspective", "relevant": false},
    {"title": "DiffDeID: a Multi-conditional Diffusion-based Method for High Fidelity Face De-indentification with Diversity", "relevant": false},
    {"title": "Distinguishing Ignorance from Error in LLM Hallucinations", "relevant": false},
    {"title": "Exploring Data Distillation for efficient generation of Tabular Data", "relevant": false},
    {"title": "GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing", "relevant": false},
    {"title": "Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction", "relevant": false},
    {"title": "CrossMPT: Cross-attention Message-passing Transformer for Error Correcting Codes", "relevant": false},
    {"title": "Integrating Expertise of Software Engineering Agents", "relevant": false},
    {"title": "VEBench: Towards Comprehensive and Automatic Evaluation for Text-guided Video Editing", "relevant": false},
    {"title": "InverseBench: Benchmarking Plug-and-Play Diffusion Models for Scientific Inverse Problems", "relevant": false},
    {"title": "ClipGrader: Leveraging Vision-Language Models for Robust Label Quality Assessment in Object Detection", "relevant": false},
    {"title": "Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon", "relevant": false},
    {"title": "Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs", "relevant": false},
    {"title": "Learning Code Preference via Synthetic Evolution", "relevant": false},
    {"title": "Selective Label Enhancement Learning for Test-Time Adaptation", "relevant": false},
    {"title": "MambaExtend: A Training-Free Approach to Improve Long Context Extension of Mamba", "relevant": false},
    {"title": "SpatialEdit: Unlocking the Spatial Capability in Multimodal Large Language Model Driven Image Editing", "relevant": false},
    {"title": "LeYOLO: Lightweight, Scalable and Efficient CNN Architecture for Object Detection", "relevant": false},
    {"title": "The VEP Booster: A Closed-Loop AI System for Visual EEG Biomarker Auto-generation", "relevant": false},
    {"title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer", "relevant": false},
    {"title": "Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation", "relevant": false},
    {"title": "Thinking Forward and Backward: Effective Backward Planning with Large Language Models", "relevant": true},
    {"title": "A SSM is Polymerized from Multivariate Time Series", "relevant": false},
    {"title": "Unified Multimodal Discrete Diffusion", "relevant": false},
    {"title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation", "relevant": false},
    {"title": "IBCircuit: Towards Holistic Circuit Discovery with Information Bottleneck", "relevant": false},
    {"title": "Adversarial Diffusion Bridge Model for Reliable Adversarial Purification", "relevant": false},
    {"title": "A Non-Contrastive Learning Framework for Sequential Recommendation with Preference-Preserving Profile Generation", "relevant": false},
    {"title": "What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis", "relevant": false},
    {"title": "ConvINT: A Semi-Structured Intention Framework for Conversational Understanding", "relevant": false},
    {"title": "RootTracker: A Lightweight Framework to Trace Original Models of Fine-tuned LLMs in Black-Box Conditions", "relevant": false},
    {"title": "Generative Matching Units for Supervised Learning", "relevant": false},
    {"title": "Nested Gloss Makes Large Language Models Lost", "relevant": false},
    {"title": "MoDeGPT: Modular Decomposition for Large Language Model Compression", "relevant": false},
    {"title": "Graphon Neural Differential Equations and Transferabilty of Graph Neural Differential Equations", "relevant": false},
    {"title": "Fight Fire with Fire: Multi-biased Interactions in Hard-Thresholding", "relevant": false}
]
