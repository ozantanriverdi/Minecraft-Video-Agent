[
    {"title": "Modeling Asynchronous Time Series with Large Language Models", "relevant": false},
    {"title": "Diffusion Active Learning: Towards Data-Driven Experimental Design in Computed Tomography", "relevant": false},
    {"title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding", "relevant": false},
    {"title": "Gating is Weighting: Understanding Gated Linear Attention through In-context Learning", "relevant": false},
    {"title": "Associative memory and dead neurons", "relevant": false},
    {"title": "From Logits to Hierarchies: Hierarchical Clustering made Simple", "relevant": false},
    {"title": "State-space models can learn in-context by gradient descent", "relevant": false},
    {"title": "The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling", "relevant": false},
    {"title": "Variance-Reduced Forward-Reflected Algorithms for  Generalized Equations", "relevant": false},
    {"title": "Functional segregation of inputs in artificial neural networks for vision", "relevant": false},
    {"title": "Towards Scalable Topological Regularizers", "relevant": false},
    {"title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models", "relevant": false},
    {"title": "Probing the contents of text, behavior, and brain data toward improving human-LLM alignment", "relevant": false},
    {"title": "CLAD: A Contrastive Learning based Method for Multi-Class Anomaly Detection", "relevant": false},
    {"title": "Scalable and Enhanced Hallucination Detection in LLMs using Semantic Clustering", "relevant": false},
    {"title": "The Foundations of Tokenization: Statistical and Computational Concerns", "relevant": false},
    {"title": "AskChart: Universal Chart Understanding through Textual Enhancement", "relevant": false},
    {"title": "On Representing Convex Quadratically Constrained Quadratic Programs via Graph Neural Networks", "relevant": false},
    {"title": "QAEncoder: Towards Aligned Representation Learning in Question Answering System", "relevant": false},
    {"title": "Variational Inference for Self-Supervised Speech Models Fine-tuning on Downstream Tasks", "relevant": false},
    {"title": "LLMs for Generalizable Language-Conditioned Policy Learning under Minimal Data Requirements", "relevant": true},
    {"title": "Implicit degree bias in the link prediction task", "relevant": false},
    {"title": "HyResPINNs: Adaptive Hybrid Residual Networks for Learning Optimal Combinations of Neural and RBF Components for Physics-Informed Modeling", "relevant": false},
    {"title": "Complete and Lipschitz continuous invariants of graphs under geometric isomorphism in R^n", "relevant": false},
    {"title": "Strategy-centric Synthesis: Connecting Billions of Image-Text Pairs to High-Quality Visual Instruction Data", "relevant": false},
    {"title": "Flow Graph Neural Networks", "relevant": false},
    {"title": "MPCache: MPC-Friendly KV Cache Eviction for Efficient Private LLM Inference", "relevant": false},
    {"title": "Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models", "relevant": true},
    {"title": "Conformal Prediction Sets Can Cause Disparate Impact", "relevant": false},
    {"title": "GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning", "relevant": false},
    {"title": "Generation Network for Echocardiographic Sectional Positioning and Shape Completion", "relevant": false},
    {"title": "Bitune: Leveraging Bidirectional Attention to Improve Decoder-Only LLMs", "relevant": false},
    {"title": "Intrinsic Dimension Correlation: uncovering nonlinear connections in multimodal representations", "relevant": false},
    {"title": "Regret-Optimal List Replicable Bandit Learning: Matching Upper and Lower Bounds", "relevant": false},
    {"title": "Jump-teaching: Ultra Robust and Efficient Learning with Noisy Labels", "relevant": false},
    {"title": "FlatQuant: Flatness Matters for LLM Quantization", "relevant": false},
    {"title": "Promptriever: Instruction-Trained Retrievers Can Be Prompted Like Language Models", "relevant": false},
    {"title": "OmniBench: Towards The Future of  Universal Omni-Language Models", "relevant": false},
    {"title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?", "relevant": false},
    {"title": "On a Hidden Property in Computational Imaging", "relevant": false},
    {"title": "Unsupervised Multi-Agent Diversity With Wasserstein Distance", "relevant": false},
    {"title": "Entropy Reveals What You Know: An Entropy-Guided Method for Enhancing the Reliability of Large Language Models", "relevant": false},
    {"title": "Linguini: A benchmark for language-agnostic linguistic reasoning", "relevant": false},
    {"title": "Mutual Information Preserving Neural Network Pruning", "relevant": false},
    {"title": "GRADE: Quantifying Sample Diversity in Text-to-Image Models", "relevant": false},
    {"title": "Language Models Need Inductive Biases to Count Inductively", "relevant": false},
    {"title": "Plan-RAG: Planning-guided Retrieval Augmented Generation", "relevant": false},
    {"title": "Automated Red Teaming with GOAT: the Generative Offensive Agent Tester", "relevant": false},
    {"title": "Gaussian Mixture Vector Quantization with Aggregated  Categorical Posterior", "relevant": false},
    {"title": "Quantifying AI Psychology: A Psychometric Benchmark for Large Language Models", "relevant": false}
]
