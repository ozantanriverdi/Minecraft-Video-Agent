[
    {"title": "Connecting Solutions and Boundary Conditions/Parameters Directly: Solving PDEs in Real Time with PINNs", "relevant": false},
    {"title": "On Erroneous Agreements of CLIP Image Embeddings", "relevant": false},
    {"title": "Neural Symbolic Regression of Complex Network Dynamics", "relevant": false},
    {"title": "SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition", "relevant": false},
    {"title": "What can Mamba do for 3D Volumetric Medical Image Segmentation?", "relevant": false},
    {"title": "Learning Semantic-Enhanced Dual Temporal Adjacent Maps for Video Moment Retrieval", "relevant": false},
    {"title": "TUI: A Conformal Uncertainty Indicator for Continual Test-Time Adaptation", "relevant": false},
    {"title": "Not All LLM Reasoners Are Created Equal", "relevant": false},
    {"title": "Pseudo-Labels are All You Need for Out-Of-Distribution Detection", "relevant": false},
    {"title": "Efficient Training of Neural Stochastic Differential Equations by Matching Finite Dimensional Distributions", "relevant": false},
    {"title": "Zero-shot Generalist Graph Anomaly Detection with Unified Neighborhood Prompts", "relevant": false},
    {"title": "Learning Diverse Attacks on Large Language Models for Robust Red-Teaming and Safety Tuning", "relevant": false},
    {"title": "TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights", "relevant": false},
    {"title": "GasketRAG: Systematic Alignment of Large Language Models with Retrievers", "relevant": false},
    {"title": "Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning", "relevant": false},
    {"title": "Looking beyond the surface with Contrastive LEarning with Anti-contrastive Regularization (CLEAR)", "relevant": false},
    {"title": "CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning", "relevant": false},
    {"title": "Enhancing Adversarial Robustness Through Robust Information Quantities", "relevant": false},
    {"title": "Gradient Flow Provably Learns Robust Classifiers for Data from Orthonormal Clusters", "relevant": false},
    {"title": "Accumulator-Aware Post-Training Quantization for Large Language Models", "relevant": false},
    {"title": "Parallel simulation for sampling under isoperimetry and score-based diffusion models", "relevant": false},
    {"title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement", "relevant": false},
    {"title": "Spectro-Riemannian Graph Neural Networks", "relevant": false},
    {"title": "CBMA: Improving Conformal Prediction through Bayesian Model Averaging", "relevant": false},
    {"title": "FLDmamba:  Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction", "relevant": false},
    {"title": "ParallelSpec: Parallel Drafter for Efficient Speculative Decoding", "relevant": false},
    {"title": "Point-SAM: Promptable 3D Segmentation Model for Point Clouds", "relevant": false},
    {"title": "Causal Discovery via Bayesian Optimization", "relevant": false},
    {"title": "Towards Out-of-Modal Generalization without Instance-level Modal Correspondence", "relevant": false},
    {"title": "A grid world agent with favorable inductive biases", "relevant": false},
    {"title": "IT 3 : Idempotent Test-Time Training", "relevant": false},
    {"title": "Uncertainty Estimation for 3D Object Detection via Evidential Learning", "relevant": false},
    {"title": "Hybrid Preference Optimization: Augmenting Direct Preference Optimization with Auxiliary Objectives", "relevant": false},
    {"title": "From Unimodal to Multimodal:Scaling up Projectors to Align Modalities", "relevant": false},
    {"title": "Data Distillation for extrapolative protein design through exact preference optimization", "relevant": false},
    {"title": "A Realistic Threat Model for Large Language Model Jailbreaks", "relevant": false},
    {"title": "Radial Basis Operator Networks", "relevant": false},
    {"title": "Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model", "relevant": false},
    {"title": "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling", "relevant": false},
    {"title": "Zero-shot Outlier Detection via Synthetically Pretrained Transformers: Model Selection Bygone!", "relevant": false},
    {"title": "SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF", "relevant": false},
    {"title": "Coordinate In and Value Out: Training Flow Transformers in Ambient Space", "relevant": false},
    {"title": "Do LLMs estimate uncertainty well in instruction-following?", "relevant": false},
    {"title": "TopoDiffusionNet: A Topology-aware Diffusion Model", "relevant": false},
    {"title": "Analyzing the Language of Visual Tokens", "relevant": false},
    {"title": "DistillHGNN: A Knowledge Distillation Approach for High-Speed Hypergraph Neural Networks", "relevant": false},
    {"title": "The Geometry of Attention: Ricci Curvature and Transformers Training and  Robustness", "relevant": false},
    {"title": "Learning Transformer-based World Models with Contrastive Predictive Coding", "relevant": false},
    {"title": "Covariate-informed continuous-time gray-box modeling to identify responsiveness of post-surgical pain to opioid therapy", "relevant": false},
    {"title": "Logical Consistency of Large Language Models in Fact-Checking", "relevant": false}
]
