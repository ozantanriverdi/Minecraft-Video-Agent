[
    {"title": "GEAR-FEN: Generalized Feature Representation for Kinematic Human Activity Recognition", "relevant": false},
    {"title": "Memory-Efficient Fine-Tuning via Structured Neural Network Pruning", "relevant": false},
    {"title": "Adaptive Batch Size for Privately Finding Second-Order Stationary Points", "relevant": false},
    {"title": "Language Models Are Implicitly Continuous", "relevant": false},
    {"title": "Make LLMs better zero-shot reasoners: structure-oriented autonomous reasoning", "relevant": false},
    {"title": "Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape View", "relevant": false},
    {"title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models", "relevant": false},
    {"title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning", "relevant": false},
    {"title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration", "relevant": false},
    {"title": "IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent through Induction, Deduction, and Abduction", "relevant": false},
    {"title": "Transformers Learn Variable-order Markov Chains in-Context", "relevant": false},
    {"title": "Information Bottleneck for Active Feature Acquisition", "relevant": false},
    {"title": "Universal Multimodal Retrieval with Multimodal LLMs", "relevant": false},
    {"title": "Spark Transformer: How Many FLOPs is a Token Worth?", "relevant": false},
    {"title": "On more accurate alignment modeling methods for automatic speech recognition", "relevant": false},
    {"title": "In Praise of Stubbornness: The Case for Cognitive-Dissonance Aware Continual Update of Knowledge in LLMs", "relevant": false},
    {"title": "RNNs are not Transformers (Yet): The Key Bottleneck on In-Context Retrieval", "relevant": false},
    {"title": "DC-Spin: A Speaker-invariant Speech Tokenizer For Spoken Language Models", "relevant": false},
    {"title": "Efficiently Identifying Watermarked Segments in Mixed-Source Texts", "relevant": false},
    {"title": "Foundation Vision Models are Unsupervised Image Canonicalizers", "relevant": false},
    {"title": "Diffusing States and Matching Scores: A New Framework for Imitation Learning", "relevant": false},
    {"title": "Linear Representations of Political Perspective Emerge in Large Language Models", "relevant": false},
    {"title": "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models", "relevant": false},
    {"title": "Towards continuous machine learning on periodic crystals by ultra-fast invariants", "relevant": false},
    {"title": "Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings", "relevant": false},
    {"title": "Small features matter: Robust representation for world models", "relevant": false},
    {"title": "Rational Metareasoning for Large Language Models", "relevant": false},
    {"title": "Context-aware Dynamic Pruning for Speech Foundation Models", "relevant": false},
    {"title": "Consistency-based Black-box Uncertainty Quantification for Text-to-SQL by Similarity Aggregation", "relevant": false},
    {"title": "From Pixels to Prose: A Large Dataset of Dense Image Captions", "relevant": false},
    {"title": "Infinite-Resolution Integral Noise Warping for Diffusion Models", "relevant": false},
    {"title": "Data-Centric Graph Condensation via Diffusion Trajectory Matching", "relevant": false},
    {"title": "Smooth Real-time Rendering via Implicit Nested Neighborhoods", "relevant": false},
    {"title": "Merging Feed-Forward Sublayers for Compressed Transformers", "relevant": false},
    {"title": "PLHF: Prompt Learning from Few-shot Human Feedback", "relevant": false},
    {"title": "Flow Matching for Accelerated Simulation of Atomic Transport in Materials", "relevant": false},
    {"title": "Coarsening to Conceal: Enabling Privacy-Preserving Federated Learning for Graph Data", "relevant": false},
    {"title": "Asymmetric Embedding Models for Hierarchical Retrieval: Provable Constructions and a Pretrain-Finetune Recipe", "relevant": false},
    {"title": "Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI", "relevant": false},
    {"title": "GRABLI: Cross-Modal Knowledge Graph Alignment for Biomedical Language Models", "relevant": false},
    {"title": "Multimodal Attributed Graphs: Benchmarking and Rethinking", "relevant": false},
    {"title": "Joint Denoising of Cryo-EM Projection Images using Polar Transformers", "relevant": false},
    {"title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs", "relevant": false},
    {"title": "Common 7B Language Models Already Possess Strong Math Capabilities", "relevant": false},
    {"title": "Injective flows for star-like manifolds", "relevant": false},
    {"title": "Balancing Efficiency and Expressiveness: Subgraph GNNs with Walk-Based Centrality", "relevant": false},
    {"title": "Exact risk curves of signSGD in High-Dimensions: quantifying preconditioning and noise-compression effects", "relevant": false},
    {"title": "Mixture of In-Context Prompters for Tabular PFNs", "relevant": false},
    {"title": "ToRL: Topology-preserving Representation Learning Of Object Deformations From Images", "relevant": false},
    {"title": "Are Large Language Models Truly Democratizing Financial Knowledge? Identifying Knowledge Gaps", "relevant": false}
]
