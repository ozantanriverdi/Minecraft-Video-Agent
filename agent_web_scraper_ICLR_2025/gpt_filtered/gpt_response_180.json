[
    {"title": "C-CLIP: Multimodal Continual Learning for Vision-Language Model", "relevant": false},
    {"title": "SpinQuant: LLM Quantization with Learned Rotations", "relevant": false},
    {"title": "LLaVA-Critic: Learning to Evaluate Multimodal Models", "relevant": false},
    {"title": "Revisit Micro-batch Clipping: Adaptive Data Pruning via Gradient Manipulation", "relevant": false},
    {"title": "Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?", "relevant": false},
    {"title": "WHAT YOU PAINT IS WHAT YOU GET", "relevant": false},
    {"title": "AnomalyTCN: Dual-branch Convolution with Contrastive Representation for Efficient Time Series Anomaly Detection", "relevant": false},
    {"title": "IMPROVING LOW-BIT POST TRAINING QUANTIZATION: A DATA-FREE APPROACH", "relevant": false},
    {"title": "Spatial-Mamba: Effective Visual State Space Models via Structure-Aware State Fusion", "relevant": false},
    {"title": "On the Optimization Landscape of Low Rank Adaptation Methods for Large Language Models", "relevant": false},
    {"title": "Automating Large-scale In-silico Benchmarking for Genomic Foundation Models", "relevant": false},
    {"title": "Output Scouting: Auditing Large Language Models for Catastrophic Responses", "relevant": false},
    {"title": "Attention-Only Transformers via Unrolled Subspace Denoising", "relevant": false},
    {"title": "LLM2CLIP: Extending the Capability Boundaries of CLIP through Large Language Models", "relevant": false},
    {"title": "Federated Class-Incremental Learning: A Hybrid Approach Using Latent Exemplars and Data-Free Techniques to Address Local and Global Forgetting", "relevant": false},
    {"title": "DriveE2E: Benchmarking Closed-Loop End-to-End Autonomous Driving Based-on Real-World Traffic Scenarios", "relevant": false},
    {"title": "VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis", "relevant": false},
    {"title": "Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning", "relevant": false},
    {"title": "Retrieval Head Mechanistically Explains Long-Context Factuality", "relevant": false},
    {"title": "LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA", "relevant": false},
    {"title": "Truth-Guided Negative Sampling in Self-supervised Graph Representation Learning", "relevant": false},
    {"title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "relevant": false},
    {"title": "Replicate and Quantize: A Plug-and-Play Strategy for Load Balancing in Sparse Mixture-of-Experts LLMs", "relevant": false},
    {"title": "Understanding the Stability-based Generalization of Personalized Federated Learning", "relevant": false},
    {"title": "H-QLoRA: Enhancing Quantized LLMs with Hierarchical Residual Learning", "relevant": false},
    {"title": "How Does Cross-Layer Correlation in Deep Neural Networks Influence Generalization and Adversarial Robustness?", "relevant": false},
    {"title": "Disentangling the QiGan Encoded by a DNN towards the Go Game", "relevant": false},
    {"title": "Think Beyond Size: Dynamic Prompting for More Effective Reasoning", "relevant": false},
    {"title": "PDDFormer: Pairwise Distance Distribution Graph Transformer for Crystal Material Property Prediction", "relevant": false},
    {"title": "Highly efficient Speech Separation using relative Context", "relevant": false},
    {"title": "Adaptive Rentention & Correction for Continual Learning", "relevant": false},
    {"title": "Unsupervised Model Tree Heritage Recovery", "relevant": false},
    {"title": "Deep Linear Probe Generators for Weight Space Learning", "relevant": false},
    {"title": "Questioning Simplicity Bias Assumptions", "relevant": false},
    {"title": "FairFedMed: Achieving Equity in Medical Federated Learning via FairLoRA", "relevant": false},
    {"title": "Efficient Gradient Clipping Methods in DP-SGD for Convolution Models", "relevant": false},
    {"title": "Do WGANs succeed because they minimize the Wasserstein Distance? Lessons from Discrete Generators", "relevant": false},
    {"title": "Neural-Symbolic Message Passing with Dynamic Pruning", "relevant": false},
    {"title": "A Visual Case Study of the Training Dynamics in Neural Networks", "relevant": false},
    {"title": "HALO: Human-Aligned End-to-end Image Retargeting with Layered Transformations", "relevant": false},
    {"title": "Temperature Optimization for Bayesian Deep Learning", "relevant": false},
    {"title": "Your Weak LLM is Secretly a Strong Teacher for Alignment", "relevant": false},
    {"title": "See Further When Clear: Adaptive Generative Modeling with Curriculum Consistency Model", "relevant": false},
    {"title": "GaussianClin: Multimodal Featured Gaussian Splatting for Dynamic Clinical Videos", "relevant": false},
    {"title": "Beyond Canonicalization: How Tensorial Messages Improve Equivariant Message Passing", "relevant": false},
    {"title": "Accelerating Diffusion Transformers with Token-wise Feature Caching", "relevant": false},
    {"title": "Towards Unified Human Motion-Language Understanding via Sparse Interpretable Characterization", "relevant": false},
    {"title": "WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models", "relevant": false},
    {"title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers", "relevant": false},
    {"title": "Intervening Anchor Token: Decoding Strategy in Alleviating Hallucinations for MLLMs", "relevant": false}
]
