[
    {"title": "Truth-value judgment in language models: belief directions are context sensitive", "relevant": false},
    {"title": "Persistent Pre-training Poisoning of LLMs", "relevant": false},
    {"title": "CipherPrune:  Efficient and Scalable Private Transformer Inference", "relevant": false},
    {"title": "Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence", "relevant": false},
    {"title": "Structural Knowledge Informed Continual Learning for Multivariate Time Series Forecasting", "relevant": false},
    {"title": "Collaborative Data Optimization", "relevant": false},
    {"title": "Monophilic Neighbourhood Transformers", "relevant": false},
    {"title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles", "relevant": false},
    {"title": "General Preference Modeling with Preference Representations for Aligning Language Models", "relevant": false},
    {"title": "Explaining Vision-Language Similarities in Dual Encoders with Feature-Pair Attributions", "relevant": false},
    {"title": "μ LO: Compute-Efficient Meta-Generalization of Learned Optimizers", "relevant": false},
    {"title": "Endowing Visual Reprogramming with Adversarial Robustness", "relevant": false},
    {"title": "SyGRID: Synthetically Generated Realistic Industrial Dataset", "relevant": false},
    {"title": "PoTable: Programming Standardly on Table-based Reasoning Like a Human Analyst", "relevant": false},
    {"title": "Multilayer Correlation Clustering", "relevant": false},
    {"title": "ALR 2 : A Retrieve-then-Reason Framework for Long-context Question Answering", "relevant": false},
    {"title": "UniEEG: Advancing Universal EEG Representation with Electrode-Wise Time-Frequency Pretraining", "relevant": false},
    {"title": "Systematic Relational Reasoning With Epistemic Graph Neural Networks", "relevant": false},
    {"title": "A Federated Graph Learning Framework With Attention Mechanism and Clustering Algorithm", "relevant": false},
    {"title": "RetroInText: A Multimodal Large Language Model Enhanced Framework for Retrosynthetic Planning via In-Context Representation Learning", "relevant": false},
    {"title": "Sinc Kolmogorov-Arnold Network and Its Applications on Physics-informed Neural Networks", "relevant": false},
    {"title": "MAC: A Multimodal Benchmark for Understanding and Generating Academic Journal Covers", "relevant": false},
    {"title": "Towards Optimizing Top- K  Ranking Metrics in Recommender Systems", "relevant": false},
    {"title": "XAIguiFormer: explainable artificial intelligence guided transformer for brain disorder identification", "relevant": false},
    {"title": "Diverse Genomic Embedding Benchmark for Functional Evaluation Across the Tree of Life", "relevant": false},
    {"title": "Vector Segmented and Recombined Adaptation for Scalable and Efficient Model Tuning", "relevant": false},
    {"title": "Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models", "relevant": false},
    {"title": "MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training", "relevant": false},
    {"title": "Optimizing Preference Alignment with Differentiable NDCG Ranking", "relevant": false},
    {"title": "Simple, Good, Fast: Self-Supervised World Models Free of Baggage", "relevant": false},
    {"title": "You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet", "relevant": false},
    {"title": "A new framework for evaluating model out-of-distribution generalisation for the biochemical domain", "relevant": false},
    {"title": "Deep Sparse Latent Feature Models for Knowledge Graph Completion", "relevant": false},
    {"title": "3DS: Decomposed Difficulty Data Selection’s Case Study on LLM Medical Domain Adaptation", "relevant": false},
    {"title": "MetaGFN: Exploring Distant Modes with Adapted Metadynamics for Continuous GFlowNets", "relevant": false},
    {"title": "Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback", "relevant": false},
    {"title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening", "relevant": false},
    {"title": "Trajectory-level Data Generation with Better Alignment for Offline Imitation Learning", "relevant": false},
    {"title": "Certified Defense Against Complex Adversarial Attacks with Dynamic Smoothing", "relevant": false},
    {"title": "Can the Training Loss be Predictive for Out-of-Distribution Generalization?", "relevant": false},
    {"title": "Long-Short Decision Transformer: Bridging Global and Local Dependencies for Generalized Decision-Making", "relevant": false},
    {"title": "What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models", "relevant": false},
    {"title": "Low-Rank Quantization-Aware Training for LLMs", "relevant": false},
    {"title": "RACCOON: Regret-based Adaptive Curricula for Cooperation", "relevant": false},
    {"title": "On the Expressiveness of Rational ReLU Neural Networks With Bounded Depth", "relevant": false},
    {"title": "Uncertainty-aware Human Mobility Modeling and Anomaly Detection", "relevant": false},
    {"title": "LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs - Evaluation through Synthetic Data Generation", "relevant": false},
    {"title": "Eliciting Black-Box Representations from LLMs through Self-Queries", "relevant": false},
    {"title": "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators", "relevant": false},
    {"title": "How does controllability emerge in language models during pretraining?", "relevant": false}
]
