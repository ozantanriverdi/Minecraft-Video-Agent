[
    {"title": "Data-Aware Training Quality Monitoring and Certification for Reliable Deep Learning", "relevant": false},
    {"title": "Benign Overfitting in Out-of-Distribution Generalization of Linear Models", "relevant": false},
    {"title": "ClimaQA: An Automated Evaluation Framework for Climate Foundation Models", "relevant": false},
    {"title": "SLIM-LLMs: Low-Rank Models of Linguistic Style", "relevant": false},
    {"title": "Disentangling and Integrating Relational and Sensory Information in Transformer Architectures", "relevant": false},
    {"title": "Failure Modes of LLMs for Causal Reasoning on Narratives", "relevant": false},
    {"title": "Task-Adaptation Curriculum Learning", "relevant": false},
    {"title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts", "relevant": false},
    {"title": "Depth Extrapolation of Decoders Trained on Nested Structures", "relevant": false},
    {"title": "Multi-Session Client-Centered Treatment Outcome Evaluation in Psychotherapy", "relevant": false},
    {"title": "3D Perception with Differentiable Map Priors", "relevant": false},
    {"title": "CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems", "relevant": false},
    {"title": "KV-Distill: Nearly Lossless Context Compression for Transformers", "relevant": false},
    {"title": "Estimating the Probabilities of Rare Outputs in Language Models", "relevant": false},
    {"title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "relevant": false},
    {"title": "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model", "relevant": true},
    {"title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution", "relevant": false},
    {"title": "Ladder Residual: Redefining Tensor Parallelism in Transformers for Accelerated Inference", "relevant": false},
    {"title": "Lossy Compression with Pretrained Diffusion Models", "relevant": false},
    {"title": "Altared Environments: The Role of Normative Infrastructure in AI Alignment", "relevant": false},
    {"title": "Human-like Episodic Memory for Infinite Context LLMs", "relevant": true},
    {"title": "Code diffusion models are continuous human noise operators", "relevant": false},
    {"title": "Beyond accuracy: understanding the performance of LLMs on exams designed for humans", "relevant": false},
    {"title": "EVOSCHEMA: TOWARDS TEXT-TO-SQL ROBUSTNESS AGAINST SCHEMA EVOLUTION", "relevant": false},
    {"title": "CAN TRANSFORMERS IN-CONTEXT LEARN BEHAVIOR OF A LINEAR DYNAMICAL SYSTEM?", "relevant": false},
    {"title": "Robustness of Truss Decomposition and Implications for GNN-based Edge Classification", "relevant": false},
    {"title": "ODE Parameter Identification: An Integral Matching Approach", "relevant": false},
    {"title": "Better Call Graphs: A New Dataset of Function Call Graphs for Malware Classification", "relevant": false},
    {"title": "What Matters in Learning from Large-Scale Datasets for Robot Manipulation", "relevant": false},
    {"title": "Leveraging Side Information with Deep Learning for Linear Inverse Problems: Applications to MR Image Reconstruction", "relevant": false},
    {"title": "Learning Discrete Latent Models from Discrete Observations", "relevant": false},
    {"title": "Diffusion Models are Few-shot Learners for Dense Vision Tasks", "relevant": false},
    {"title": "Rapidly Adapting Policies to the Real-World via Simulation-Guided Fine-Tuning", "relevant": false},
    {"title": "TrajGPT: Irregular Time-Series Representation Learning for Health Trajectory Analysis", "relevant": false},
    {"title": "Fed-REACT: Federated Representation Learning for Heterogeneous Time Series Data", "relevant": false},
    {"title": "Learning to Discover Regulatory Elements for Gene Expression Prediction", "relevant": false},
    {"title": "Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents", "relevant": true},
    {"title": "OCEBO: Object-Centric Pretraining by Target Encoder Bootstrapping", "relevant": false},
    {"title": "Modality-Specialized Synergizers for Interleaved Vision-Language Generalists", "relevant": false},
    {"title": "Coarse Correspondences Boost 3D Spacetime Understanding in Multimodal Language Model", "relevant": false},
    {"title": "Zero Shot Generalization of Vision-Based RL Without Data Augmentation", "relevant": false},
    {"title": "Network-based Active Inference and its Application in Robotics", "relevant": false},
    {"title": "LASER: Attention using Exponential Transformation", "relevant": false},
    {"title": "ZoomVLM: A Tuning-Free Framework for Efficient Video Understanding via Adaptive Zooming in Vision-Language Models", "relevant": false},
    {"title": "Distilling an End-to-End Voice Assistant Without Instruction Training Data", "relevant": false},
    {"title": "Replay can provably increase forgetting", "relevant": false},
    {"title": "PIT-QMM: A Large Multimodal Model for No-Reference Point Cloud Quality Assessment", "relevant": false},
    {"title": "Network-based Active Inference for Adaptive and Cost-efficient Real-World Applications: PV Panel Inspection", "relevant": false},
    {"title": "Deep Learning Aided Broadcast Codes With Feedback", "relevant": false},
    {"title": "Quality Measures for Dynamic Graph Generative Models", "relevant": false}
]
